{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_oc82Mij-9T"
      },
      "source": [
        "# **Import**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9eyI37-Hj-9U"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Import required libraries\n",
        "\"\"\"\n",
        "!pip install rasterio\n",
        "\n",
        "\n",
        "# Raster processing\n",
        "import rasterio\n",
        "\n",
        "# Data handling\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Deep learning (TensorFlow and Keras)\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.layers import (\n",
        "    Input, Conv2D, Conv3D, ConvLSTM2D, concatenate, BatchNormalization,\n",
        "    Dense, SeparableConv2D, Activation, Dropout, TimeDistributed\n",
        ")\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "# Visualization\n",
        "from tensorflow.keras.utils import plot_model\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Evaluation and time measurement\n",
        "import time\n",
        "\n",
        "# File handling and preprocessing\n",
        "import os\n",
        "import re\n",
        "import glob\n",
        "from scipy.ndimage import rotate\n",
        "import random\n",
        "\n",
        "# Type hinting\n",
        "from typing import overload"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def set_global_determinism(seed=42):\n",
        "    \"\"\"\n",
        "    Fix all seeds for Python, NumPy, and TensorFlow to ensure (as much as possible)\n",
        "    reproducible results, including GPU determinism if possible.\n",
        "    \"\"\"\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "\n",
        "set_global_determinism(seed=42)"
      ],
      "metadata": {
        "id": "ZS7exOHFxSCn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dz5bdxQlj-9V"
      },
      "source": [
        "# **Data loader**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def min_max_scaler(x: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Scale the input array x to the range [0, 1] using min-max normalization.\n",
        "\n",
        "    Args:\n",
        "        x (np.ndarray): Input array.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Scaled array in range [0, 1].\n",
        "    \"\"\"\n",
        "    x_min = np.min(x)\n",
        "    x_max = np.max(x)\n",
        "    return (x - x_min) / (x_max - x_min + 1e-10)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Custom Dataset Class for Spatio-Temporal City Growth Modeling\n",
        "This class loads multi-year .tif files, constructs time-windowed samples,\n",
        "performs optional augmentation (flip, rotation), and splits into patches if needed.\n",
        "\"\"\"\n",
        "class CityGrowthDataset:\n",
        "    def __init__(self,\n",
        "                 data_dir: str,\n",
        "                 years: list,\n",
        "                 channels: list,\n",
        "                 window_size: int = 2,\n",
        "                 patch_size: int = 20,\n",
        "                 overlap: int = 10,\n",
        "                 rotation_angle: int = 15,\n",
        "                 do_flip: bool = True,\n",
        "                 random_seed: int = 42):\n",
        "        \"\"\"\n",
        "        Initialize the dataset with parameters.\n",
        "\n",
        "        Args:\n",
        "            data_dir (str): The directory path containing .tif files.\n",
        "            years (list): A sorted list of years (e.g. [1980, 1990, 2000, 2010]).\n",
        "            channels (list): List of channel names to load (e.g. ['lc1','lc2',...]).\n",
        "            window_size (int): Number of consecutive years to use as input.\n",
        "            patch_size (int): The size of patches to extract. If None or 0, no patch splitting.\n",
        "            overlap (int): Overlap size between adjacent patches.\n",
        "            rotation_angle (int): The step size (in degrees) for discrete rotation candidates.\n",
        "                                  0 means no rotation.\n",
        "            do_flip (bool): Whether to apply random flipping horizontally and vertically.\n",
        "            random_seed (int): Seed for reproducibility in random operations.\n",
        "        \"\"\"\n",
        "        self.data_dir = data_dir\n",
        "        self.years = sorted(years)\n",
        "        self.channels = channels\n",
        "        self.window_size = window_size\n",
        "        self.patch_size = patch_size\n",
        "        self.overlap = overlap\n",
        "        self.rotation_angle = rotation_angle\n",
        "        self.do_flip = do_flip\n",
        "        np.random.seed(random_seed)\n",
        "        self.data_dict = self._load_all_data()\n",
        "        self.samples = self._create_time_window_samples()\n",
        "\n",
        "    def _load_all_data(self) -> dict:\n",
        "        \"\"\"\n",
        "        Load all .tif files and stack channels for each year.\n",
        "        Each channel is min-max scaled.\n",
        "\n",
        "        Returns:\n",
        "            dict: Mapping from each year to a numpy array (H, W, num_channels).\n",
        "        \"\"\"\n",
        "        data_dict = {}\n",
        "        all_tifs = glob.glob(os.path.join(self.data_dir, '*.tif'))\n",
        "\n",
        "        year_pattern = re.compile(r'.*_(\\d{4})_')\n",
        "        file_map = {}\n",
        "        for tif_path in all_tifs:\n",
        "            base = os.path.basename(tif_path)\n",
        "            match = year_pattern.match(base)\n",
        "            if not match:\n",
        "                continue\n",
        "            year_str = match.group(1)\n",
        "            year_int = int(year_str)\n",
        "\n",
        "            ch_str = base.split('_')[-1].replace('.tif', '')\n",
        "            file_map[(year_int, ch_str)] = tif_path\n",
        "\n",
        "\n",
        "        for year in self.years:\n",
        "            channel_arrays = []\n",
        "            for ch in self.channels:\n",
        "                if (year, ch) not in file_map:\n",
        "                    raise ValueError(f\"Missing file for year={year}, channel={ch}\")\n",
        "                tif_path = file_map[(year, ch)]\n",
        "                with rasterio.open(tif_path) as src:\n",
        "                    arr = src.read(1)\n",
        "                    arr = arr.astype(np.float32)\n",
        "\n",
        "                arr = min_max_scaler(arr)\n",
        "                channel_arrays.append(arr)\n",
        "\n",
        "            stacked = np.stack(channel_arrays, axis=-1)\n",
        "            data_dict[year] = stacked\n",
        "\n",
        "        return data_dict\n",
        "\n",
        "    def _create_time_window_samples(self) -> list:\n",
        "        samples = []\n",
        "        for i in range(len(self.years) - self.window_size):\n",
        "            x_years = self.years[i:i+self.window_size]\n",
        "            y_year = self.years[i+self.window_size]\n",
        "\n",
        "            X = np.stack([self.data_dict[y] for y in x_years], axis=0)\n",
        "\n",
        "            lc1_idx = self.channels.index('lc1')\n",
        "            Y = self.data_dict[y_year][..., lc1_idx:lc1_idx+1]\n",
        "\n",
        "            samples.append((X, Y))\n",
        "        return samples\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx: int):\n",
        "        \"\"\"\n",
        "        Returns a single sample (or multiple patches) at index idx.\n",
        "        - Applies data augmentation (flip, rotation) to the entire sample.\n",
        "        - Splits into patches if patch_size is specified.\n",
        "        - Converts each patch to tf.Tensor.\n",
        "\n",
        "        Returns:\n",
        "            (list_of_X_tensors, list_of_Y_tensors):\n",
        "                Each X_tensor has shape (window_size, patch_H, patch_W, C).\n",
        "                Each Y_tensor has shape (patch_H, patch_W, 1).\n",
        "        \"\"\"\n",
        "        X, Y = self.samples[idx]\n",
        "        X_aug, Y_aug = self._augment(X, Y)\n",
        "        X_patches, Y_patches = self._patch_split(X_aug, Y_aug)\n",
        "\n",
        "        X_tensors = [tf.convert_to_tensor(xp, dtype=tf.float32) for xp in X_patches]\n",
        "        Y_tensors = [tf.convert_to_tensor(yp, dtype=tf.float32) for yp in Y_patches]\n",
        "        return X_tensors, Y_tensors\n",
        "\n",
        "    def _augment(self, X: np.ndarray, Y: np.ndarray):\n",
        "        \"\"\"\n",
        "        Apply data augmentation to input X and target Y.\n",
        "        - Flip horizontally/vertically with 50% chance if do_flip=True.\n",
        "        - Rotate by a discrete angle multiple if rotation_angle > 0.\n",
        "        - Outside region after rotation is masked to 0.\n",
        "        \"\"\"\n",
        "        if self.do_flip:\n",
        "            if np.random.rand() < 0.5:\n",
        "                X = np.flip(X, axis=1)\n",
        "                Y = np.flip(Y, axis=0)\n",
        "            if np.random.rand() < 0.5:\n",
        "                X = np.flip(X, axis=2)\n",
        "                Y = np.flip(Y, axis=1)\n",
        "\n",
        "\n",
        "        if self.rotation_angle > 0:\n",
        "            possible_angles = np.arange(0, 360, self.rotation_angle)\n",
        "            angle = np.random.choice(possible_angles)\n",
        "\n",
        "            rotated_X = []\n",
        "            for t in range(X.shape[0]):\n",
        "                x_t = X[t]\n",
        "                mask = np.ones(x_t.shape[:2], dtype=np.float32)\n",
        "                x_rot = rotate(x_t, angle=angle, axes=(0,1), reshape=False,\n",
        "                               order=1, mode='constant', cval=0)\n",
        "                m_rot = rotate(mask, angle=angle, axes=(0,1), reshape=False,\n",
        "                               order=0, mode='constant', cval=0)\n",
        "                x_rot = x_rot * m_rot[..., np.newaxis]  # mask out-of-bound\n",
        "                rotated_X.append(x_rot)\n",
        "            X = np.stack(rotated_X, axis=0)\n",
        "\n",
        "            mask_y = np.ones(Y.shape[:2], dtype=np.float32)\n",
        "            y_rot = rotate(Y, angle=angle, axes=(0,1), reshape=False,\n",
        "                           order=1, mode='constant', cval=0)\n",
        "            m_y_rot = rotate(mask_y, angle=angle, axes=(0,1), reshape=False,\n",
        "                             order=0, mode='constant', cval=0)\n",
        "            Y = y_rot * m_y_rot[..., np.newaxis]\n",
        "\n",
        "        return X, Y\n",
        "\n",
        "    def _patch_split(self, X: np.ndarray, Y: np.ndarray):\n",
        "        \"\"\"\n",
        "        Split the input X and Y into patches of size patch_size x patch_size,\n",
        "        with the specified overlap. If patch_size=None or 0, return the original image as is.\n",
        "        If patch_size is None or 0, do not split.\n",
        "\n",
        "        Args:\n",
        "            X (np.ndarray): Input volume shape (time, H, W, C).\n",
        "            Y (np.ndarray): Target shape (H, W, 1).\n",
        "\n",
        "        Returns:\n",
        "            (X_patches, Y_patches): Lists of np.ndarray patches.\n",
        "                Each X patch: (time, patch_size, patch_size, C)\n",
        "                Each Y patch: (patch_size, patch_size, 1)\n",
        "        \"\"\"\n",
        "        if not self.patch_size:\n",
        "            return [X], [Y]\n",
        "\n",
        "        X_patches = []\n",
        "        Y_patches = []\n",
        "        _, H, W, _ = X.shape\n",
        "        step = self.patch_size - self.overlap\n",
        "\n",
        "        for i in range(0, H - self.patch_size + 1, step):\n",
        "            for j in range(0, W - self.patch_size + 1, step):\n",
        "                X_patch = X[:, i:i+self.patch_size, j:j+self.patch_size, :]\n",
        "                Y_patch = Y[i:i+self.patch_size, j:j+self.patch_size, :]\n",
        "                X_patches.append(X_patch)\n",
        "                Y_patches.append(Y_patch)\n",
        "\n",
        "        return X_patches, Y_patches"
      ],
      "metadata": {
        "id": "DCJuo2B7MKDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_directory = \"your/data/path/Variables\"\n",
        "channels = ['lc1','lc2','lc3','lc4','lc6', 'lc7',\n",
        "            'acc1','acc2','acc3','acc4','acc6','acc7',\n",
        "            'accsws','accic','accwater']\n",
        "\n",
        "patch_size = None\n",
        "overlap = 0\n",
        "rotation_angle = 90\n",
        "do_flip = True\n",
        "\n",
        "train_dataset = CityGrowthDataset(\n",
        "    data_dir = data_directory,\n",
        "    years     = [1980, 1990, 2000],\n",
        "    channels  = channels,\n",
        "    window_size     = 2,\n",
        "    patch_size      = patch_size,\n",
        "    overlap         = overlap,\n",
        "    rotation_angle  = rotation_angle,\n",
        "    do_flip         = do_flip,\n",
        "    random_seed     = 42\n",
        ")\n",
        "\n",
        "test_dataset = CityGrowthDataset(\n",
        "    data_dir = data_directory,\n",
        "    years     = [1990, 2000, 2010],\n",
        "    channels  = channels,\n",
        "    window_size     = 2,\n",
        "    patch_size      = patch_size,\n",
        "    overlap         = overlap,\n",
        "    rotation_angle  = 0,\n",
        "    do_flip         = False,\n",
        "    random_seed     = 42\n",
        ")\n",
        "\n",
        "X_patches, Y_patches = train_dataset[0]\n",
        "\n",
        "print(\"Number of time-window samples in dataset:\", len(train_dataset))\n",
        "print(\"Number of patches in sample[0]:\", len(X_patches))\n",
        "print(\"X_patches[0] shape:\", X_patches[0].shape, \"Y_patches[0] shape:\", Y_patches[0].shape)"
      ],
      "metadata": {
        "id": "MkE_HNhqalzZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_generator():\n",
        "    X_list, Y_list = train_dataset[0]\n",
        "    for X_t, Y_t in zip(X_list, Y_list):\n",
        "        yield X_t, Y_t\n",
        "\n",
        "def test_generator():\n",
        "    X_list, Y_list = test_dataset[0]\n",
        "    for X_t, Y_t in zip(X_list, Y_list):\n",
        "        yield X_t, Y_t\n",
        "\n",
        "batch_size = 4\n",
        "\n",
        "train_ds = tf.data.Dataset.from_generator(\n",
        "    train_generator,\n",
        "    output_signature=(\n",
        "        tf.TensorSpec(shape=(2, patch_size, patch_size, 15), dtype=tf.float32),\n",
        "        tf.TensorSpec(shape=(patch_size, patch_size, 1), dtype=tf.float32)\n",
        "    )).batch(batch_size)\n",
        "\n",
        "test_ds  = tf.data.Dataset.from_generator(\n",
        "    test_generator,\n",
        "    output_signature=(\n",
        "        tf.TensorSpec(shape=(2, patch_size, patch_size, 15), dtype=tf.float32),\n",
        "        tf.TensorSpec(shape=(patch_size, patch_size, 1), dtype=tf.float32)\n",
        "    )).batch(batch_size)"
      ],
      "metadata": {
        "id": "KeWOyQrahfug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for step, (X_batch, Y_batch) in enumerate(train_ds):\n",
        "    print(\"Train step:\", step)\n",
        "    print(\"X_batch.shape:\", X_batch.shape)  # (batch_size, seq_len, patch_size, patch_size, channels)\n",
        "    print(\"Y_batch.shape:\", Y_batch.shape)  # (batch_size, patch_size, patch_size, 1)\n",
        "    break\n",
        "\n",
        "for step, (X_batch, Y_batch) in enumerate(test_ds):\n",
        "    print(\"Test step:\", step)\n",
        "    print(\"X_batch.shape:\", X_batch.shape)\n",
        "    print(\"Y_batch.shape:\", Y_batch.shape)\n",
        "    break"
      ],
      "metadata": {
        "id": "rS0xIQgvjBbG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for X_patch, Y_patch in train_generator():\n",
        "    print(\"X_patch.shape:\", X_patch.shape, \"Y_patch.shape:\", Y_patch.shape)\n",
        "    break"
      ],
      "metadata": {
        "id": "-GQSX2oOi1CG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFuM7egcj-9f"
      },
      "source": [
        "# **Network Model**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def acc(y_true, y_pred):\n",
        "    y_pred_bin = tf.cast(y_pred >= 0.5, tf.float32)\n",
        "    return tf.reduce_mean(tf.cast(tf.equal(y_true, y_pred_bin), tf.float32))\n",
        "\n",
        "def f1_score(y_true, y_pred):\n",
        "    y_pred_bin = tf.cast(y_pred >= 0.5, tf.float32)\n",
        "    tp = tf.reduce_sum(y_true * y_pred_bin)\n",
        "    fp = tf.reduce_sum((1 - y_true) * y_pred_bin)\n",
        "    fn = tf.reduce_sum(y_true * (1 - y_pred_bin))\n",
        "    precision = tp / (tp + fp + 1e-7)\n",
        "    recall = tp / (tp + fn + 1e-7)\n",
        "    f1 = 2 * precision * recall / (precision + recall + 1e-7)\n",
        "    return f1"
      ],
      "metadata": {
        "id": "iXyKA7EzXIqC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWzRpEJ4j-9f"
      },
      "source": [
        "## **Hyper-parameters**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xzCFH1Rvj-9f"
      },
      "outputs": [],
      "source": [
        "kn_s = 3\n",
        "dsfilter1 = 8\n",
        "dsfilter2 = 4\n",
        "filter1 = 30\n",
        "filter2 = 20\n",
        "unit1 = 4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_len = X_patch.shape[0]\n",
        "input_row = X_patch.shape[1]\n",
        "input_col = X_patch.shape[2]\n",
        "input_chan = X_patch.shape[3]\n",
        "\n",
        "seq_len, input_row, input_col, input_chan"
      ],
      "metadata": {
        "id": "7F9IRmnMXLfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioftHOHNj-9f"
      },
      "source": [
        "## **Modeling**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Layer\n",
        "\n",
        "class ReflectionPadding2DTime(Layer):\n",
        "    \"\"\"\n",
        "    A custom layer to perform REFLECT padding on the spatial dimensions.\n",
        "    Supports both 4D (batch, H, W, C) and 5D (batch, time, H, W, C) inputs.\n",
        "    \"\"\"\n",
        "    def __init__(self, pad=(1,1), **kwargs):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            pad: tuple of (pad_height, pad_width)\n",
        "        \"\"\"\n",
        "        super().__init__(**kwargs)\n",
        "        self.pad = pad\n",
        "\n",
        "    def call(self, x):\n",
        "        ph, pw = self.pad\n",
        "        input_rank = len(x.shape)\n",
        "\n",
        "        if input_rank == 5:\n",
        "            paddings = [[0,0], [0,0], [ph, ph], [pw, pw], [0,0]]\n",
        "        elif input_rank == 4:\n",
        "            paddings = [[0,0], [ph, ph], [pw, pw], [0,0]]\n",
        "        else:\n",
        "            raise ValueError(\"ReflectionPadding2DTime supports only 4D or 5D tensors.\")\n",
        "\n",
        "        return tf.pad(x, paddings=paddings, mode='REFLECT')\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        ph, pw = self.pad\n",
        "        input_shape = tf.TensorShape(input_shape).as_list()\n",
        "        if len(input_shape) == 5:\n",
        "            batch, time, h, w, c = input_shape\n",
        "            h = h + 2*ph if h is not None else None\n",
        "            w = w + 2*pw if w is not None else None\n",
        "            return (batch, time, h, w, c)\n",
        "        elif len(input_shape) == 4:\n",
        "            batch, h, w, c = input_shape\n",
        "            h = h + 2*ph if h is not None else None\n",
        "            w = w + 2*pw if w is not None else None\n",
        "            return (batch, h, w, c)\n",
        "        else:\n",
        "            raise ValueError(\"Input shape must be 4D or 5D.\")"
      ],
      "metadata": {
        "id": "SJkP8iQBXQjV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.device('/GPU:0'):\n",
        "\n",
        "    inputs = Input(shape=(seq_len, input_row, input_col, input_chan), name='Input')\n",
        "    DSC = ReflectionPadding2DTime(pad=(kn_s//2, kn_s//2))(inputs)\n",
        "    DSC = TimeDistributed(SeparableConv2D(filters=dsfilter1, kernel_size=kn_s, padding='valid'))(DSC)\n",
        "    DSC = TimeDistributed(BatchNormalization())(DSC)\n",
        "\n",
        "    DSC = ReflectionPadding2DTime(pad=(kn_s//2, kn_s//2))(DSC)\n",
        "    DSC = TimeDistributed(SeparableConv2D(filters=dsfilter2, kernel_size=kn_s, padding='valid'))(DSC)\n",
        "    DSC = TimeDistributed(BatchNormalization())(DSC)\n",
        "\n",
        "    DSC = ReflectionPadding2DTime(pad=(kn_s//2, kn_s//2))(DSC)\n",
        "    DSC = TimeDistributed(Conv2D(1, kernel_size=kn_s, padding='valid', activation='sigmoid'))(DSC)\n",
        "\n",
        "    DS_Conv_LSTM = ReflectionPadding2DTime(pad=(kn_s//2, kn_s//2))(DSC)\n",
        "    DS_Conv_LSTM = ConvLSTM2D(filters=filter1, kernel_size=kn_s, padding='valid', return_sequences=True, activation='tanh')(DS_Conv_LSTM)\n",
        "    DS_Conv_LSTM = BatchNormalization()(DS_Conv_LSTM)\n",
        "\n",
        "    DS_Conv_LSTM = ReflectionPadding2DTime(pad=(kn_s//2, kn_s//2))(DS_Conv_LSTM)\n",
        "    DS_Conv_LSTM = ConvLSTM2D(filters=filter2, kernel_size=kn_s, padding='valid', return_sequences=False, activation='tanh')(DS_Conv_LSTM)\n",
        "    DS_Conv_LSTM = BatchNormalization()(DS_Conv_LSTM)\n",
        "\n",
        "    DS_Conv_LSTM = TimeDistributed(Dense(units=unit1, activation='relu'))(DS_Conv_LSTM)\n",
        "\n",
        "    DS_Conv_LSTM = ReflectionPadding2DTime(pad=(kn_s//2, kn_s//2))(DS_Conv_LSTM)\n",
        "    Output = Conv2D(1, kernel_size=(kn_s, kn_s), padding='valid', activation='sigmoid')(DS_Conv_LSTM)\n",
        "\n",
        "    DS_ConvLSTM_Model = Model(inputs=input, outputs = Output)\n",
        "    DS_ConvLSTM_Model.compile(loss='mse', optimizer='adam', metrics=[acc, f1_score, 'mse'])\n",
        "\n",
        "DS_ConvLSTM_Model.summary()"
      ],
      "metadata": {
        "id": "zLu3N-EwS22l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Model Train**"
      ],
      "metadata": {
        "id": "G9n4o1BxU7Cs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.device('/device:GPU:0'):\n",
        "  start = time.time()\n",
        "  epochs = 1000\n",
        "  earlystop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    restore_best_weights=True\n",
        "  )\n",
        "\n",
        "  checkpoint_loss = ModelCheckpoint(\n",
        "      filepath='your/data/path/Urban_Growth_Model_hanam/best_loss_ds_convlstm.h5',\n",
        "      monitor='val_loss',\n",
        "      save_best_only=True,\n",
        "      mode='min',\n",
        "      verbose=1\n",
        "  )\n",
        "\n",
        "  checkpoint_f1 = ModelCheckpoint(\n",
        "      filepath='your/data/path/Urban_Growth_Model_hanam/best_f1_ds_convlstm.h5',\n",
        "      monitor='val_f1_score',\n",
        "      save_best_only=True,\n",
        "      mode='max',\n",
        "      verbose=1\n",
        "  )\n",
        "\n",
        "  hist = DS_ConvLSTM_Model.fit(\n",
        "    train_ds,\n",
        "    epochs=epochs,\n",
        "    validation_data=test_ds,\n",
        "    callbacks=[checkpoint_loss, checkpoint_f1, earlystop]\n",
        "    )\n",
        "\n",
        "  end = time.time()\n",
        "  how_long = end - start\n",
        "\n",
        "print(how_long // 3600, ' hours', (how_long % 3600) // 60, ' miniutes')"
      ],
      "metadata": {
        "id": "yuDFK7-JS2z-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SE4D5Dqfj-9g"
      },
      "source": [
        "## **Result**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0L6lyyjj-9g"
      },
      "source": [
        "### *Graph*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VMz3t-NIj-9g"
      },
      "outputs": [],
      "source": [
        "fig, loss_ax = plt.subplots()\n",
        "\n",
        "loss_ax.plot(hist.history['loss'], 'r', label='train loss')\n",
        "loss_ax.plot(hist.history['val_loss'],'y--', label='val loss')\n",
        "\n",
        "loss_ax.set_xlabel('epoch')\n",
        "loss_ax.set_ylabel('loss')\n",
        "\n",
        "loss_ax.legend(loc='upper right')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8UgzrKvqj-9g"
      },
      "outputs": [],
      "source": [
        "fig, acc_ax = plt.subplots()\n",
        "\n",
        "acc_ax.plot(hist.history['acc'], 'b', label='train acc')\n",
        "acc_ax.plot(hist.history['val_acc'],'g--', label='val acc')\n",
        "\n",
        "acc_ax.set_xlabel('epoch')\n",
        "acc_ax.set_ylabel('accuracy')\n",
        "\n",
        "acc_ax.legend(loc='lower right')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, acc_ax = plt.subplots()\n",
        "\n",
        "acc_ax.plot(hist.history['f1_score'], 'b', label='train f1_score')\n",
        "acc_ax.plot(hist.history['val_f1_score'],'g--', label='val f1_score')\n",
        "\n",
        "acc_ax.set_xlabel('epoch')\n",
        "acc_ax.set_ylabel('accuracy')\n",
        "\n",
        "acc_ax.legend(loc='lower right')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EFGBJUKSUEsG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2RclZlhj-9g"
      },
      "source": [
        "### *Map*"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "\n",
        "model_path = 'your/data/path/Urban_Growth_Model_hanam/best_f1_ds_convlstm.h5'\n",
        "model = tf.keras.models.load_model(\n",
        "    model_path,\n",
        "    custom_objects={\n",
        "        'acc': acc,\n",
        "        'f1_score': f1_score,\n",
        "        'mse': MeanSquaredError(),\n",
        "        'ReflectionPadding2DTime': ReflectionPadding2DTime\n",
        "    })"
      ],
      "metadata": {
        "id": "M7flw6KaUKli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_list, Y_list = test_dataset [0]\n",
        "print(f\"Number of patches in test sample[0]: {len(X_list)}\")\n",
        "\n",
        "X_patch = X_list[0]\n",
        "Y_patch = Y_list[0]\n",
        "\n",
        "print(\"X_patch shape:\", X_patch.shape)\n",
        "print(\"Y_patch shape:\", Y_patch.shape)"
      ],
      "metadata": {
        "id": "7yc80INSURun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_input = tf.expand_dims(X_patch, axis=0)\n",
        "\n",
        "pred = model.predict(X_input)\n",
        "pred_map = pred[0]\n",
        "\n",
        "print(\"pred_map shape:\", pred_map.shape)"
      ],
      "metadata": {
        "id": "BIVs7n-pURsD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "im_1990 = X_patch[0, :, :, 0]\n",
        "im_2000 = X_patch[1, :, :, 0]\n",
        "\n",
        "pred_2010 = pred_map[..., 0]\n",
        "\n",
        "gt_2010 = Y_patch[..., 0]"
      ],
      "metadata": {
        "id": "zSrEvnS4URpt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12, 3))\n",
        "\n",
        "plt.subplot(1, 4, 1)\n",
        "plt.imshow(im_1990, cmap='gray')\n",
        "plt.title(\"1990 lc1 (Input)\")\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1, 4, 2)\n",
        "plt.imshow(im_2000, cmap='gray')\n",
        "plt.title(\"2000 lc1 (Input)\")\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1, 4, 3)\n",
        "plt.imshow(pred_2010, cmap='gray', vmin=0, vmax=1)\n",
        "plt.title(\"Predicted Probability\")\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1, 4, 4)\n",
        "plt.imshow(gt_2010, cmap='gray')\n",
        "plt.title(\"2010 lc1 (Ground Truth)\")\n",
        "plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Y0kFlg5pUV-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xt9E-uGBUj70"
      },
      "source": [
        "# **Output to GIS**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import rasterio\n",
        "import tensorflow as tf\n",
        "\n",
        "def min_max_scaler(x: np.ndarray) -> np.ndarray:\n",
        "    x_min = np.min(x)\n",
        "    x_max = np.max(x)\n",
        "    return (x - x_min) / (x_max - x_min + 1e-10)\n",
        "\n",
        "\n",
        "def load_year_stack(year, channels):\n",
        "    channel_arrays = []\n",
        "    for ch in channels:\n",
        "        path = f\"your/data/path/Urban_Growth_Model_hanam/Variables/hn_{year}_{ch}.tif\"\n",
        "        with rasterio.open(path) as src:\n",
        "            arr = src.read(1).astype(np.float32)\n",
        "        arr = min_max_scaler(arr)\n",
        "        channel_arrays.append(arr)\n",
        "    stacked = np.stack(channel_arrays, axis=-1)\n",
        "    return stacked\n",
        "\n",
        "\n",
        "def split_into_patches(X, patch_size=30, overlap=10):\n",
        "    \"\"\"\n",
        "    Split input X (shape=(time, H, W, C)) into patches.\n",
        "    Returns:\n",
        "      - patches: list of patches of shape (time, patch_size, patch_size, C)\n",
        "      - origins: list of (i, j) indicating the top-left coordinate of each patch in the original image.\n",
        "    \"\"\"\n",
        "    t, H, W, C = X.shape\n",
        "    step = patch_size - overlap\n",
        "    patches = []\n",
        "    origins = []\n",
        "    for i in range(0, H - patch_size + 1, step):\n",
        "        for j in range(0, W - patch_size + 1, step):\n",
        "            patch = X[:, i:i+patch_size, j:j+patch_size, :]\n",
        "            patches.append(patch)\n",
        "            origins.append((i, j))\n",
        "    return patches, origins\n",
        "\n",
        "def predict_full_image(model, X_full, patch_size=30, overlap=10):\n",
        "    \"\"\"\n",
        "    Given a full input image X_full of shape (time, H, W, C),\n",
        "    predict the output map using a sliding window approach if patch_size is specified.\n",
        "    Overlapping areas are averaged.\n",
        "\n",
        "    Returns:\n",
        "      pred_canvas: predicted map of shape (H, W)\n",
        "    \"\"\"\n",
        "    t, H, W, C = X_full.shape\n",
        "    if patch_size is None or patch_size == 0:\n",
        "        X_input = np.expand_dims(X_full, axis=0)\n",
        "        pred = model.predict(X_input)\n",
        "        pred_map = np.squeeze(pred, axis=(0, -1))\n",
        "        return pred_map\n",
        "\n",
        "    patches, origins = split_into_patches(X_full, patch_size, overlap)\n",
        "    pred_canvas = np.zeros((H, W), dtype=np.float32)\n",
        "    count_canvas = np.zeros((H, W), dtype=np.float32)\n",
        "\n",
        "    for patch, (i, j) in zip(patches, origins):\n",
        "        patch_input = np.expand_dims(patch, axis=0)\n",
        "        patch_pred = model.predict(patch_input)\n",
        "        patch_pred_map = np.squeeze(patch_pred, axis=(0, -1))\n",
        "        pred_canvas[i:i+patch_size, j:j+patch_size] += patch_pred_map\n",
        "        count_canvas[i:i+patch_size, j:j+patch_size] += 1.0\n",
        "\n",
        "    pred_canvas[count_canvas > 0] /= count_canvas[count_canvas > 0]\n",
        "    return pred_canvas\n",
        "\n",
        "\n",
        "def unified_predict(model, X_full, patch_size, overlap):\n",
        "    \"\"\"\n",
        "    Predict full image map from input X_full (shape=(time, H, W, C)) using either\n",
        "    full image prediction (if patch_size is None or 0) or patch-based prediction.\n",
        "    \"\"\"\n",
        "    return predict_full_image(model, X_full, patch_size, overlap)\n",
        "\n",
        "\n",
        "def save_predicted_map(pred_map, reference_tif, output_tif):\n",
        "    with rasterio.open(reference_tif) as src:\n",
        "        profile = src.profile.copy()\n",
        "    profile.update({'count': 1, 'dtype': 'float32'})\n",
        "    with rasterio.open(output_tif, 'w', **profile) as dst:\n",
        "        dst.write(pred_map.astype(np.float32), 1)\n",
        "    print(f\"Saved predicted map to {output_tif}\")"
      ],
      "metadata": {
        "id": "WC7OKcFXUj71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reference_tif = \"your/data/path/Urban_Growth_Model_hanam/Variables/hn_1980_lc1.tif\"\n",
        "output2010_tif = \"your/data/path/Urban_Growth_Model_hanam/Pred_10s_DSConvLSTM.tif\"\n",
        "output2020_tif = \"your/data/path/Urban_Growth_Model_hanam/Pred_20s_DSConvLSTM.tif\"\n",
        "\n",
        "channels = ['lc1','lc2','lc3','lc4','lc6','lc7',\n",
        "            'acc1','acc2','acc3','acc4','acc6','acc7',\n",
        "            'accsws','accic','accwater']\n",
        "\n",
        "X_1990 = load_year_stack(1990, channels)\n",
        "X_2000 = load_year_stack(2000, channels)\n",
        "X_2010 = load_year_stack(2010, channels)\n",
        "\n",
        "X_full_2010 = np.stack([X_1990, X_2000], axis=0)\n",
        "X_full_2020 = np.stack([X_2000, X_2010], axis=0)\n",
        "\n",
        "pred_map_2010 = unified_predict(model, X_full_2010, patch_size, overlap)\n",
        "pred_map_2020 = unified_predict(model, X_full_2020, patch_size, overlap)\n",
        "\n",
        "save_predicted_map(pred_map_2010, reference_tif, output2010_tif)\n",
        "save_predicted_map(pred_map_2020, reference_tif, output2020_tif)"
      ],
      "metadata": {
        "id": "Y9EvmeQ0IpZg"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}